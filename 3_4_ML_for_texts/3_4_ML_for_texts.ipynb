{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {}, 
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\lugma\\anaconda3\\envs\\practicum\\lib\\site-packages (1.4.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lugma\\anaconda3\\envs\\practicum\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\lugma\\anaconda3\\envs\\practicum\\lib\\site-packages (from pandas) (1.22.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\lugma\\anaconda3\\envs\\practicum\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lugma\\anaconda3\\envs\\practicum\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\lugma\\anaconda3\\envs\\practicum\\lib\\site-packages (3.7)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\lugma\\anaconda3\\envs\\practicum\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: joblib in c:\\users\\lugma\\anaconda3\\envs\\practicum\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lugma\\anaconda3\\envs\\practicum\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: click in c:\\users\\lugma\\anaconda3\\envs\\practicum\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\lugma\\anaconda3\\envs\\practicum\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas --upgrade\n",
    "%pip install nltk --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lugma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lugma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lugma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\lugma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth1 = 'toxic_comments.csv'\n",
    "pth2 = '/datasets/toxic_comments.csv'\n",
    "    \n",
    "if os.path.exists(pth1):\n",
    "    df = pd.read_csv(pth1)\n",
    "elif os.path.exists(pth2):\n",
    "    df = pd.read_csv(pth2)\n",
    "else:\n",
    "    print('Something is wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В наборе данных около 160 тыс. комментариев. Пропуски отсутствуют. Проверим наличие дублей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим баланс классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898321\n",
       "1    0.101679\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data=df, x='toxic')\n",
    "plt.title('')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токсичных комментариев существенно меньше, чем позитивных или нейтральных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим в данных только буквенные символы, приведем все к нижнему регистру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_column = df['text'].apply(lambda text: ' '.join(re.sub(r'[^a-zA-Z ]', ' ', text).lower().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         explanation why the edits made under my userna...\n",
       "1         d aww he matches this background colour i m se...\n",
       "2         hey man i m really not trying to edit war it s...\n",
       "3         more i can t make any real suggestions on impr...\n",
       "4         you sir are my hero any chance you remember wh...\n",
       "                                ...                        \n",
       "159566    and for the second time of asking when your vi...\n",
       "159567    you should be ashamed of yourself that is a ho...\n",
       "159568    spitzer umm theres no actual article for prost...\n",
       "159569    and it looks like it was actually you who put ...\n",
       "159570    and i really don t think you understand i came...\n",
       "Name: text, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Произведем токенизацию текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_column = text_column.apply(lambda text: word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [explanation, why, the, edits, made, under, my...\n",
       "1    [d, aww, he, matches, this, background, colour...\n",
       "2    [hey, man, i, m, really, not, trying, to, edit...\n",
       "3    [more, i, can, t, make, any, real, suggestions...\n",
       "4    [you, sir, are, my, hero, any, chance, you, re...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_column[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем лемматизацию текста средствами библиотеки nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_column = token_column.apply(lambda token: ' '.join([lemmatizer.lemmatize(word) for word in token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    explanation why the edits made under my userna...\n",
       "1    d aww he match this background colour i m seem...\n",
       "2    hey man i m really not trying to edit war it s...\n",
       "3    more i can t make any real suggestion on impro...\n",
       "4    you sir are my hero any chance you remember wh...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_column[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим обучающий и текстовый выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, text_test, y_train, y_test = train_test_split(lemma_column, y, test_size=0.2, random_state=555)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим список стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = list(stopwords.words('english'))\n",
    "stop_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим несколько способов предварительной подготовки корпуса: с использованием мешка слов и параметра TF-IDF, с отсечением стоп-слов и без отсечения, а также с использованием только униграмм и совместно униграмм и биграмм.  \n",
    "Подготовим соответствующие пайпланы и произведем оценку на модели Логистической Регрессии на кросс-валидации по обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "pipeline_cnt = make_pipeline(CountVectorizer(), lgr_model)\n",
    "pipeline_cnt_2 = make_pipeline(CountVectorizer(ngram_range=(1,2)), lgr_model)\n",
    "pipeline_cnt_stop = make_pipeline(CountVectorizer(stop_words=stop_words), lgr_model)\n",
    "pipeline_cnt_stop_2 = make_pipeline(CountVectorizer(stop_words=stop_words, ngram_range=(1,2)), lgr_model)\n",
    "\n",
    "\n",
    "pipeline_tfidf = make_pipeline(TfidfVectorizer(), lgr_model)\n",
    "pipeline_tfidf_2 = make_pipeline(TfidfVectorizer(ngram_range=(1,2)), lgr_model) \n",
    "pipeline_tfidf_stop = make_pipeline(TfidfVectorizer(stop_words=stop_words), lgr_model)\n",
    "pipeline_tfidf_stop_2 = make_pipeline(TfidfVectorizer(stop_words=stop_words, ngram_range=(1,2)), lgr_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_list = [pipeline_cnt, pipeline_cnt_2, pipeline_cnt_stop, pipeline_cnt_stop_2, \n",
    "                    pipeline_tfidf, pipeline_tfidf_2, pipeline_tfidf_stop, pipeline_tfidf_stop_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Pipeline.get_params of Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(class_weight='balanced'))])>\n",
      "F1-score = 0.76, training_time = 61.0\n",
      "\n",
      "<bound method Pipeline.get_params of Pipeline(steps=[('countvectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(class_weight='balanced'))])>\n",
      "F1-score = 0.79, training_time = 225.7\n",
      "\n",
      "<bound method Pipeline.get_params of Pipeline(steps=[('countvectorizer',\n",
      "                 CountVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we',\n",
      "                                             'our', 'ours', 'ourselves', 'you',\n",
      "                                             \"you're\", \"you've\", \"you'll\",\n",
      "                                             \"you'd\", 'your', 'yours',\n",
      "                                             'yourself', 'yourselves', 'he',\n",
      "                                             'him', 'his', 'himself', 'she',\n",
      "                                             \"she's\", 'her', 'hers', 'herself',\n",
      "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(class_weight='balanced'))])>\n",
      "F1-score = 0.75, training_time = 26.5\n",
      "\n",
      "<bound method Pipeline.get_params of Pipeline(steps=[('countvectorizer',\n",
      "                 CountVectorizer(ngram_range=(1, 2),\n",
      "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
      "                                             'our', 'ours', 'ourselves', 'you',\n",
      "                                             \"you're\", \"you've\", \"you'll\",\n",
      "                                             \"you'd\", 'your', 'yours',\n",
      "                                             'yourself', 'yourselves', 'he',\n",
      "                                             'him', 'his', 'himself', 'she',\n",
      "                                             \"she's\", 'her', 'hers', 'herself',\n",
      "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(class_weight='balanced'))])>\n",
      "F1-score = 0.78, training_time = 142.2\n",
      "\n",
      "<bound method Pipeline.get_params of Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(class_weight='balanced'))])>\n",
      "F1-score = 0.74, training_time = 25.9\n",
      "\n",
      "<bound method Pipeline.get_params of Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(ngram_range=(1, 2))),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(class_weight='balanced'))])>\n",
      "F1-score = 0.74, training_time = 114.4\n",
      "\n",
      "<bound method Pipeline.get_params of Pipeline(steps=[('tfidfvectorizer',\n",
      "                 TfidfVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we',\n",
      "                                             'our', 'ours', 'ourselves', 'you',\n",
      "                                             \"you're\", \"you've\", \"you'll\",\n",
      "                                             \"you'd\", 'your', 'yours',\n",
      "                                             'yourself', 'yourselves', 'he',\n",
      "                                             'him', 'his', 'himself', 'she',\n",
      "                                             \"she's\", 'her', 'hers', 'herself',\n",
      "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(class_weight='balanced'))])>\n",
      "F1-score = 0.74, training_time = 26.1\n",
      "\n",
      "<bound method Pipeline.get_params of Pipeline(steps=[('tfidfvectorizer',\n",
      "                 TfidfVectorizer(ngram_range=(1, 2),\n",
      "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
      "                                             'our', 'ours', 'ourselves', 'you',\n",
      "                                             \"you're\", \"you've\", \"you'll\",\n",
      "                                             \"you'd\", 'your', 'yours',\n",
      "                                             'yourself', 'yourselves', 'he',\n",
      "                                             'him', 'his', 'himself', 'she',\n",
      "                                             \"she's\", 'her', 'hers', 'herself',\n",
      "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(class_weight='balanced'))])>\n",
      "F1-score = 0.74, training_time = 109.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pipeline in pipeline_list:\n",
    "    print(pipeline.get_params)\n",
    "\n",
    "    start_time = time.time()\n",
    "    f1 = cross_val_score(pipeline, X=text_train, y=y_train, cv=3, scoring='f1'). mean()\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    print(f'F1-score = {round(f1, 2)}, training_time = {round(training_time, 1)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При использовании CountVectorize добавление биграмм несколько повышает качество модели, однако сильно увеличивает время расчета. Применение стоп-слов несколько ухудшает качество модели, практически не отражаясь на скорости обучения. При использовании TfidfVectorizer качество модели практически не зависит от добавления биграмм и стоп-слов. Метод CountVectorize обеспечивает более высокую метрику качества F1-score, по сравнению с TF-IDF.  \n",
    "Таким образом, наиболее предпочтитетельная подготовка вектора признаков в данном случае основана на использовании метода мешка слов на основе униграмм и биграмм без использования стоп-слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем также  для выбранного метода подготовки данных, использовать модели классификации с дефолтными параметрами: Дерево Решений, k-ближайших и Логистическую Регрессию со Стохастическим Градиентным Спуском."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Модель Дерева Решений\n",
    "\n",
    "pipeline_dtf = make_pipeline(CountVectorizer(ngram_range=(1,2)), DecisionTreeClassifier(random_state=555, \n",
    "                                                                                        class_weight='balanced'))\n",
    "cross_val_score(pipeline_dtf, X=text_train, y=y_train, cv=3, scoring='f1', n_jobs=-1).mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Модель k-Ближайших соседей\n",
    "\n",
    "pipeline_knn = make_pipeline(CountVectorizer(ngram_range=(1,2)), KNeighborsClassifier())\n",
    "cross_val_score(pipeline_knn, X=text_train, y=y_train, cv=3, scoring='f1', n_jobs=-1).mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Логистическая Регрессия с SGD\n",
    "\n",
    "pipeline_sgd = make_pipeline(CountVectorizer(ngram_range=(1,2)), SGDClassifier(random_state=555, \n",
    "                                                                                        class_weight='balanced'))\n",
    "cross_val_score(pipeline_sgd, X=text_train, y=y_train, cv=3, scoring='f1', n_jobs=-1).mean().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество моделей Дерево Решений и k-ближайших соседей существенно ниже. Вариант Лостической Регрессии со Стохастическим Градиентным Спуском показывает несколько меньшее значение метрики качества, однако существенно выигрывает во врмени.  \n",
    "Остановимся на моделях Логистической Регрессии, попробуем настроить гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7869823266466877"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_grid = {'logisticregression__C' : np.logspace(-2, 3, 10)}\n",
    "log_search = GridSearchCV(estimator=pipeline_cnt_2, \n",
    "                            param_grid = log_grid, \n",
    "                            cv=3,\n",
    "                            n_jobs = -1,\n",
    "                            scoring='f1')\n",
    "log_search.fit(text_train, y_train)\n",
    "round(log_search.best_score_, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_grid = {'sgdclassifier__loss':['hinge', 'log'],\n",
    "            'sgdclassifier__learning_rate':['optimal', 'adaptive'],\n",
    "            'sgdclassifier__eta0':[0.05, 0.1, 0.2, 0.5]}\n",
    "sgd_search = GridSearchCV(estimator=pipeline_sgd, \n",
    "                            param_grid = sgd_grid, \n",
    "                            cv=3,\n",
    "                            n_jobs = -1,\n",
    "                            scoring='f1')\n",
    "sgd_search.fit(text_train, y_train)\n",
    "round(sgd_search.best_score_, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sgdclassifier__eta0': 0.2,\n",
       " 'sgdclassifier__learning_rate': 'adaptive',\n",
       " 'sgdclassifier__loss': 'hinge'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбор гиперпараметров несколько повысил качество модели SGD. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модели Логистической Регрессии на полном наборе обучающих данных и рассчитаем метрику f1 на тестовом наборе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 33s\n",
      "Wall time: 1min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.789630793401414"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "log_search.best_estimator_.fit(text_train, y_train)\n",
    "y_pred = log_search.best_estimator_.predict(text_test)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 29.5 s\n",
      "Wall time: 28.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7843262185409366"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sgd_search.best_estimator_.fit(text_train, y_train)\n",
    "y_pred = sgd_search.best_estimator_.predict(text_test)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика F1 на тестовых данных, соответствует аналогичным показателям на обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходный набор текстовых данных подготовлен для задачи классификации: удалены лишние символы, произведена токенизация и лемматизация текста, сформирована отложенная выборка. На модели логистической регрессии проверено несколько вариантов подготовки векторов признаков из исходного корпуса: с использованием мешка слов и TF-IDF, со стоп-словами и без, а также с разделением на униграммы и биграммы и только на униграммы. Выбран способ подготовки с использованием CountVectorizer, без стоп-слов и на основе униграмм и биграмм. \n",
    "Проверено несколько других методов классификации: Деревья Решений, k-ближайших соседей и Логистическая регрессия со стохастическим Градиентным Спуском. Наилучшее значение метрики качества F1 на обучающей выборке на кросс-валидации получено на Логистической Регрессии, применение метода SGD несколько снижает качество, однако дает выигрыш в скорости расчета. Выбранные модели протестированы на отложенной выборке, метрика f1 составила 0,78 - 0,79, что примерно соответствует качеству на обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63f113a1601180346c35c6ea86e47f04905aea8361ea206af11938e7b7ec1a20"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('practicum')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
